---
# Branch maimul
title: "Parents’ Educational Background and Children’s Success"
author: "Maimul"
date: '2022-05-04'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(psych)
library("codebook")
```


### Load file to r as dataframe
```{r}
df1 <- read.csv('~/Documents/Principle of DS/Project/datasets/student-mat.csv') # Change this according to the file name and directory of the file.
df2 <- df1
```



### Explore the dataset
```{r}
dim(df1) # Check the dimension of the dataset

# glimpse is better than str(). More organised, easy to read. 
# Also dim f(x) is baked into the glimpse.
glimpse(df1) # from tidyverse

# Explore the column names
names(df1)

# Before checking for missing values, list all unique values in the dataframe. Look for "" cells
unique(unlist(df1))
```
There are no empty cells to impute. Example: "" to NA

```{r}
# Check for missing data in df1
print(colSums(is.na(df1)))
```
No NA values. 

```{r}
# Before we change the datatypes we must check the unique values in each column.
lapply(df1, unique) # lapply always returns a list. 
```


### Change the datatype of each column accordingly 
```{r}
# List columns that should be factor (not ordered)
col_factors <- c('school', 'sex', 'address','Pstatus','Mjob','Fjob','reason','guardian')
df1[col_factors] <- lapply(df1[col_factors], factor)

# List columns that should be factor (ordered)
col_factorsO <- c('famsize')
df1[col_factorsO] <- lapply(df1[col_factorsO], ordered, levels = c('LE3','GT3'))

# List columns that should be binary
col_binary <- c('schoolsup','famsup','paid','activities','nursery','higher','internet','romantic')
df1[col_binary]  <- ifelse(df1[col_binary] == 'yes',1,0)
df1[col_binary]  <- lapply(df1[col_binary], as.logical)

```

```{r}
# 4. Check for missing data
sum(is.na(df1))

# 5. If data is clean, randomly generate NA to the df1 dataset
na.gen <- function(data, n){
  i <- 1
  while(i < n+1){
    index1 <- sample(1:nrow(data), 1)
    index2 <- sample(1:ncol(data), 1)
    data[index1, index2] <- NA
    i = i+1
  }
  return(data)
}

# 6. Generate 50 NAs to the df1 randomly
df1 <- na.gen(df1, 50)

# 7. Check again for missing data
sum(is.na(df1))

# 8. List number of missing data in column
colSums(is.na(df1))

# 9 List rows with missing data
missingdata <- df1[!complete.cases(df1), ]
sum(is.na(missingdata))

# 10. Median imputation for numerical data & Mode imputation for categorical data
df1.impute <- df1
for (i in which(sapply(df1.impute, is.numeric))){
  df1.impute[is.na(df1.impute[, i]), i] <- median(df1.impute[, i], na.rm = TRUE)
}
sum(is.na(df1.impute))

# 11. Ientify duplicate row
duplicated(df1.impute)
sum(duplicated(df1.impute))

# 12. Observe invalid values
describe(df1.impute)
```



# Descriptive Analysis
```{r}
summary(df1)
sum(is.na(df1))
```

